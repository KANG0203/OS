##  2pg.

Multi-object Program
- 각각의 object가 자신의 lock과 cv를 가져야 한다.
- 뭐 필요한거 슥 적어둔 듯 뒤에 나오겠지

## 4pg.

Topic
- multiprocessor cache coherence
- MCS locks(locks이 주로 busy일때 즉 사용중일때)
- RCU locks(locks가 주로 busy이고, data가 주로 read-only일때)

## 5pg.

Multiprocessor cahce coherence(캐시 일관성)  

시나리오
- thread A는 critical section에서 data를 수정했고 lock을 해제
- threa B가 lock을 얻고 data 읽기
- 모든 access가 main memory를 이용하연 쉽다.

## 6pg.

Write-back Cache Coherence

Cache coherence
- system은 data의 copy가 있는 것처럼 행동한다.
- data가 read되는 경우, 여러 cache에서 copy를 가질 수 있다.
- data가 modify되는 경우, 최대 한 cache만 copy 가능.

On write
- write하기 전에 모든 cached copy들을 invalidate한다.
- 수정된 data는 cache에 남아있다.
저게 바로 write back이다.
어짜피 도느니는 아키 안들어서 모를테니 설명하고 넘어간다.
write back과 write through가 상반된 개념이다.
write back은 main memory에 쓰는 것이 아니라 cache에 써두었다가, 필요할 때 main memory를 업데이트 하는 방식이다.
write through는 cache와 main memory에 둘 다 쓰는 것이다.

On read
- 값을 owner나 memory에서 가져온다.

## 7pg.

걍 슥 보고 넘어가자.  

## 8pg.

Directory-based Cache Coherence  

cached location을 어떻게 알까
- H/W는 모든 cached copy를 추적한다.
- read miss 발생 시, 최근 copy를 가져와서 invalidate
- write miss 발생 시, 모든 copy invalidate

Read-modify-write instructions
– cache entry를 독점적으로 가져와, complete될 때까지 다른 cache가 data를 읽지 못하게 한다.  

## 9pg.

앞에서 보았던 spinlock으로 보호.

## 10pg.

대충 보기.  

## 11pg.

Reducing lock contention(경쟁)  

Fine-gained locking
- object를 subset으로 나누어, 각각이 자신의 lock으로 보호된다.

Per-processor data structure
- object를 분할하여 대부분의 access가 한 processor에서 이루어짐.

Ownership/staged architecture
- 한번에 하나의 thread만 shared data를 access

## 12pg.

What if Locks are still mostly busy?  

MCS lock
- lock이 경쟁할때를 위해 lock 구현 최적화

RCU(read-copy-update)
- 효율적인 readers,writers lock(in linux)
- reader는 first acquiring lock 없이 진행한다.
- writer는 reader가 끝났음을 보장한다.

둘다 atomic read-modify-write instructions 의존.  

## 13pg.

앞 ppt에서 spinlock인가 할 때 등장했던 test_and_set이다.  
test하고 원래 값을 return하며, 값을 busy(true)로 바꿔둔다.  

만약 많은 processor가 동시에 lock을 acquire하면 어떻게 될까
- T&S는 많은 cache coherency traffic을 발생한다.
- lock을 경쟁하는 cpu간의 FIFO 순서를 보장 안한다.

## 14pg.

뭐 대충 P1이 lock을 가지고 있어서 P2랑 P3가 t&s 실행하고 update 못하고 있는 상황인 것 같다.  

## 15pg ~ 17pg.

이제 t&S에 test를 하나 더 추가한 코드이다.  

만약 많은 processor가 동시에 lock을 acquire하면 어떻게 될까
- 아직 T&S에 의존
- lock을 경쟁하는 cpu간의 FIFO 순서를 보장 안한다.
- Lock value pings between caches 

Test를 하나 더 추가하면 왜 더 성능이 좋을까?
- 아마 다음 page 그림을 봐서는 일단 test를 먼저 해서 t&s을 실행 안해도 되는 경우를 미리 거르는 작업을 해주는 것 같다.


## 18pg.

spin lock에 delay를 준다
- 도음은 되지만 경쟁이 없다면 느려진다.

Spin adaptively
- waiting이 적으면 no delay
- waiting 많으면 long delay -> wait time으로 waiter의 수 추정

MCS
- compareAndSwap을 이용하여 waiters의 linked list를 만든다.
- processor당 location에 spin

## 19pg.

Atomic compareAndSwap
- memory word에서 작동
- memory word 값이 예상과 다른지 확인한다.(다르지 않다면 다른 thread들이 compareAndSwap을 먼저 실행 안한거다)
- changed되었다면 return an error(and loop)
- not changed면, memory word를 new value로 set

## 20pg.

MCS lock  

lock을 waiting하는 thread list를 유지한다.
- list의 front가 lock을 hold
- MCSLock::tail은 list의 last thread
- new thread는 compareAndSwap을 이용하여 tail에 추가된다.
- lock은  next->needToWait = FALSE;으로 새팅되어 넘어간다.
- next thread는 자신의 needToWait가 true이면 spin

## 21pg ~ 22pg.

acquire 함수를 보자.
- compareAndSwap으로 변하지 않으면 oldtail = tail
- 만약 oldTail != Null이면 기다려야 하므로 oldtail->next를 mytcb로 정해주고, needToWait가 false가 될 때까지 spin

release 함수를 보자.
- if 문으로 change 되었다면, tail == MyTCB인 경우 마지막이니깐 free
- else 문으로 myTCB->next가 NULL이 될 떄까지 spin될고 next의 needtoWait을 false로 만들어준다.

## 23pg.

RCU(Read-Copy-Update)  

shared data를 빠르게 읽는 것을 목표로 한다.
- first acquiring a lock 없이 read 진행
- write가 느려도 괜찮다.

Restricted update
- writer는 data structure의 new version 계산
- new version을 single atomic instrcution으로 publish

Multiple concurrent version
- reader는 old나 new version을 볼 수 있다.

integeration with thread scheduler
- 모든 reader가 grace period 안에 끝나는 것을 보장하고, old version을 garbage collect한다.

## 24pg.

이제 grace period 전에는 old version을 read한다.  
write가 끝나면 new version이 되고, grace period아네서 read를 하면 new version을 읽는다.  
만약 grace period 전에 read 하는데 version이 new가 되면 old나 new를 read하게 된다.  
만약 grace period가 끝나면 old version을 garbage collect 한다.  

## 25pg.

reader는 entry에서 interrupt를 비활성화 한다.
- 이는 critical section에서 read가 재때 완료될 것을 보장한다.
- read or write lock이 없다.

Writer
- write lock 을 얻는다.
- new sata structure 계산
- new version을 atomic instruction으로 publish
- release write lock
- grace period동안 wait
- wait 끝나면 old version garbage collect

## 26pg.

Non-blocking synchronization  

목표 : data structure가 lock 없이 읽고 수정할 수 있게 한다.
- lock 경쟁이 없고 deadlock이 발생 안한다.

일반적인 방법은 compareandswap을 이용하는 것이다.
- data structure copy를 만든다.
- copy를 수정한다
- 아무도 접근 안하면 new version으로 swap
- pointer가 변경된 경우 다시 시작

## 28pg.

Deadlock Definition  

Resource : thread가 일을 하는데 필요한 모든 것(cpu, disk space, memory, lock)
- Preemptable : OS에 의해 가져가진다.
- Non-preemptable : thread와 무조건 leave

Starvation : 계속 wait  

Deadlock : resource를 circular wait
- Deadlock -> starvation 반대는 성립 안함.

## 29pg.

그림 보면 두번째 줄에서 서로 lock 얻으려고 wait한다. 

## 30pg.

cv 사용한 모습.

## 31pg.

먹으려면 젓가락 두개 있어야 한다.  

## 32pg.

Deadlock 조건
- resource 제한적
- preemption 없다
- hold and wait -> 기다리는 동안 resoucre holding
- request의 circular chain

## 33pg.

Dining Philosophers problem은 위의 deadlock 조건을 만족한다.  
deadlock을 피하기 막기 위해 어떻게 수정해야 할까?  

## 34pg.

Prevent : exploit or limit program behavior
- deadlock으로 이어지는 어떠한 행동도 프로그램이 수행 못하게 제한

Avoid : 미래 예측
- program이 무엇을 할 지 알면 deadlock이 발생하는지 파악할 수 있다.

Detect and recover
- thread를 rollback할 수 있다면, deadlock이 발생한 후에도 해결할 수 있다.

## 35pg.

Exploit or Limit Behavior : “Prevent"  
- 충분한 자원 공급  
- holding할 때 wait 제거, 모튤 호출할 때 lock release
- circular waiting 제거, 고정된 순서로 lock acquire

## 36pg.

지금 보면 deadlock이 발생하고 있다.  
이를 해결하기 위해 위에서 말했듯이 고정된 순서로 lock acquire(ex> A B C)  

## 37pg.

System Model  
- Ri 는 Resource
- 각각의 resource는 W의 instance를 가진다.
- 모든 process는 request -> use(acquire) -> release 순으로 이용

## 38pg.

RAG : Resource Allocation Graph  

vertex
- P : process
- R : resource, 안에 동그라미는 instance

Edge
- request E : P -> R
- assignment E : R -> P

## 39pg.

cycle이 발생한다고 무조건 Deadlock이 아니다.  

첫번째 그림 보면 cycle에 관여하는 모든 process가 wait 상태임 즉 deadlock  
두번째 그림 보면 P2는 wait 상태가 아니다. 그래서 P2가 release하면 P1의 wait는 끝난다. 즉 no deadlock  

## 40pg.

no cycle in RAG -> no deadlock  

cycle 발생
- instance가 1개면 cycle == deadlock
- multi instance면 아님.

## 41pg ~ 43pg.

보면 j번째에 deadlock이 형성되어 있다.  
43pg.에서 B requests S 를 제거하여 deadlock 해결  

## 44pg.

E는 존재하는 resource  
A는 이용 가능한 resource  
C는 process n에 할당되어있는 것들  
R는 process n이 필요한 것들  

## 45pg.

앞글자만 따겠다.  

E를 보면 T가 4개, P가 2개, S가 3개, 1이 1개 존재한다.  

현재 이용 가능한 resource는 A를 보면 각각 2개 1개 0개 0개 이다.  

C를 보자. 현재 process는 3개 존재하고, process1이 S를 1개, process2가 T 2개, C 1개, process3이 P 1개, S 2개를 이용중이다.  

음 걍 내 생각을 적어보면...  

우선 어떤 process가 resource를 가져가는지에 따라 deadlock이 발생할 수 있고, 안할 수 있다.  

Deadlock이 발생 안하는 상황은 아마 Process3가 T를 2개 다 가져가는 경우일 것이다.  
process3은 T와 P를 요청하는데, P는 1개 남아있어서 wait안하고 acquire한다.  
process1과 2는 둘다 wait를 무조건 해야 하는 상황이다.  
그래서 wait 안해도 되는 process3이 가져가야지, release하면 다음 process가 쓸 수 있을 것이다.  

## 46pg.

system이 deadlock state에 들어가지 않도록 보장한다. (deadlock prevent and avoid)
- problem : device 이용율 저하, throughput 감소
- avoidance도 resource needs 예측이 필요하다.

system이 deadlock 상태로 진입하고, 회복 가능하게 한다. (detect & recover)
- 비용 많이 소모, 회복 불가할 수 있음.

problem을 무시하고 deadlock이 발생 안할 것이라고 가정한다.  

## 47page

safe state
- 미래 자원 요청에 대한 어떠한 가능한 순서도, 결국 승인이 가능하다.
- 자원을 이용할 때 wait가 필요할 수 있다.

unsafe state
- 자원 요청의 sequence가 deadlock의 결과를 낳을 수 있다.

doomed state
- 모든 결과가 deadlock

## 48pg.

Deadlock Avoidance  

observation 1 : safe state는 deadlock이 안된다.  
obseravtion 2 : 요청 delay가 safe state를 unsafe state로 바꾸지 않는다.  

scheme
- process가 이용 가능한 resource를 요청할 때, 요청을 승인하면 unsafe state로 가는지 채크해라.(predict the future), 만약 그러면 delay 시켜라.
- deadlock avoidance algorithem : single instance면 RAG, multiple instance면 banker 알고리즘

## 49pg.

single instance
- RAG 사용
- 만약 request로 인해 cycle생기면 not grant

## multi instanse -> banker's algorithm
- 각 thread마다 최대 몇개 resource 필요한지 미리 알려준다.
- 자원을 요청할 때, unsafe state, 즉 dead lock으로 이어질 수 있기 때문에 자원이 이용 가능하더라도 wait할 수도 있다.
- thread가 모든 자원을 획득하면, 유한 시간 내에 return 해야한다.

## 50pg.

Data Structures for Banker’s Algorithm  

n = number of process  
m = number of resource type  

Available : length m인 vector, Avail[j] = k 면 j resource중 k개의 instanse 이용 가능  

Max : n*m, Max[i,j] = k면 i Process가 j resource를 최대 k개 요청 가능.  

Allocation : n*m, Alloc[i,j] = k면 i process가 현재 j resource중 k개가 현재 할당되어있다.  

Need : n*m, Need[i,j] = k면 i process가 완료하기 위해 j resource가 k개 더 필요하다  

Need[i,j] = Max[i,j] - Alloc[i,j]  

## 51pg ~ 52pg.

Bancker's Algorithm  

우선 class를 보면 r과 t는 각각 # of resource, thread를 뜻함.  

Request 함수를 보자.
- lock을 얻어서 mutual exclusion하게 한다.
- whlie문으로 요청했을 때 안전하지 않으면 wait를 건다. 조건 함수는 뒤에서 다시 확인하자
- 만약 안전하면 alloc를 ++, avail -- 한다.
- assert 함수를 통해 safe하지 않으면 error를 발생한다.

WoulBesafe 함수를 보자
- 일단 할당을 해본다.
- 만약 할당했을 때 safe하면 result를 true로 바꾼다.
- 다시 원상복귀한다.
- return한다

isSafe 함수를 보자. 이게 핵심임
- 일단 avail을 카피한 tobeavail을 만들고, need를 계산하고, finish를 만든느데 이거는 모두 false로 한다. finish의 length는 thread의 개수이겟지?
- 그리고 while 문 시작.
- 우선 j를 뽑아야 하는데, 이 j는 finish[j]가 false이고, 모든 resource i에 대해서 need보다 tobeAvail이 큰 경우, 즉 필요한거보다 이용할 수 있는게 더 많은 경우의 j를 뽑는다.
- 이제 이 j 가 존재하면? else 로 가서 safe하다는 뜻이니 finish를 true로 하고, 이제 자 핵심이다
- 모든 resource i에 대해 toBeavail[i] = toBeAvail[i] + alloc[i][j]를 한다. 이게 무슨 뜻이냐 하면 일단 이 j thread는 safe하니 자신이 가진 resource를 다를 thread에 줄 수 있다는 뜻이다. 그래서 자신이 할당받은 alloc[i][j]를 이용 가능하다고 주는 것이다.
- 이제 이걸 반복해서 j가 안나올 때, if문으로 가서 finish가 모두 true 즉 모든 thread가 safe한 경우 true를 return, 아니면 false를 return한다.


  ## 53pg.

  걍 그림보고 이해 끝~
