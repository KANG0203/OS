## 2pg.

Main points  

file system
- physical device 위의 유용한 추상화

storage 하드웨어 특성
- disk 및 flash memory
- availability and RAID(Redundant Array of Inexpensive Disks)

## 3pg.

File Systems  

top of persisent storage 위의 추상화
- magnetic disk
- flash memory

devices provide
- machine crash후에도 살아남는 storage
- block level(random) access
- 낮은 비용으로 대용량
- 비교적 느린 성능 -> magentic disk read가 느린듯

## 4pg.

Hiding Details of Physical Storage  

file system에 저장된 data의 지속성
- update 중 충돌 발생해도
- disk block이 손상되어도
- flash memory가 소모되어도

naming
- disk block number 대신에 named data
- flat storage 대신 directory
- device가 block 지향적이지만 byte addressable data

성능
- cached data
- data 배치 및 data 구조 조직

shared data에 대한 controlled access  

## 5pg.

File System Abstraction  

file system
- persistent named data
- 계층 구조(directory)
- data에 대한 access 제어

file - data의 named collection
- bytes의 선형 sequence(or set of sequences)
- R/W or mmap

crash, stroage error 허용
- OS crash라도 file system은 valid state로 남음

성능
- 평균적인 경우 하드웨어 한계에 근접

## 6pg.

Storage Devices  

Magnetic disks
- 드물게 손상되는 storage
- 낮은 비용으로 large capacity
- block level의 random access
- random access에 대한 느린 성능
- streaming access(sequence)에 대한 좋은 성능 -> 즉 random이냐 sequence냐에 영향 받음

Flash memory
- 드물게 손상되는 storage
- 중간 비용으로 capacity 확보
- block level의 random access
- read에 성능 좋고, random write에 성능 안좋음 -> 즉 R/W에 영향 받음

## 7pg.

A Typical Disk Controller  

External connection  

cache
- disk와 I/O bus간의 buffer data

controller
- R/W의 세부 사항
- cache 대체 알고리즘
- 실패 감지 및 복구

## 8pg.

Caching Inside a Disk Controller
- 최근 access한 block을 cache하는 DRAM 있음 -> 7pg 그림 보기
- 일반적으로 cache entry는 LRU로 교체

Pros
- access에 지역성 있으면 read에 좋음

cons
- 비용 높음
- reliable write 처리 필요

## 9pg.

Magnetic Disk
- disk surface: 자성 물질로 코팅된 원형 disk
- track: disk 표면 주위의 동심원 형태의 고리, 각 track을 따라 bit가 일렬로 배치
- sector: 각 track이 track의 부채꼴로 나눠짐(전송의 최소 unit)

## 10pg.

Disk tracks  

사용되지 않은 guard region으로 분리
- write중 out track이 손상되는 가능성 줄임

track 길이는 disk 전체에 걸쳐 다름
- outside: track 당 sector가 더 많아 bancwidth 큼
- disk는 같은 sector/track으로 구성된 영역으로 나뉨
- 반지름의 외부 반만 사용 -> disk의 대부분 영역이 disk의 외부에 위치

## 11pg.

Sectors  

sector는 sophisticated error correcting codes 포함 -> sector 사이에 interference 있을 수 있음. 이를 해결
- disk head magnet의 field가 track보다 넓다
- 이웃하는 track에 대한 쓰기로 인한 손상을 숨긴다

Sector sparing
- bad sector를 동일한 surface의 spare sector에 투명하게 표시

Slip sparing
- 모든 sector(만약 bad sector가 있는 경우)를 다시 mapping하여 sequential behavior를 보여줌

track skewing
- 순차적인 작업을 위해 disk head 이동을 허용하기 위해 track에서 track으로의 sector 번호를 offset으로 설정

## 12 ~ 13pg.

![image](https://github.com/KANG0203/OS/assets/144585363/bb0c9f53-9f7f-4ba7-9d93-54d0ff9ff8d0)

head crash -> disk head가 disk surface에 접촉하는 상황(충격이나 진동에 취약)  

Magnetic disk는 disk pack으로 구성  
Cylinder: platter의 특정 track  
disk arm: disk arm이 disk head 운반   

seek: head가 올바른 track으로 이동  
rotational: sector가 head 아래로 오도록 회전  
transfer: disk와 memory간의 data 전송  

disk access time = seek time + rotational latency + transfer time  

## 14pg.

disk access time = seek time + rotational latency + transfer time  

seek time
- dick arm을 track 위로 이동하는데 걸리는 시간
- head가 안정화되기 위한 미세한 위치 조정 필요
- 현재 disk에서는 head 전환 시간이 track 전환 시간과 거의 동일

rotational latency
- disk가 disk head 아래로 회전할 때 기다리는 시간
- 평균적으로 반 회전만 기다린다

transfer time
- disk로 data를 전송하거나, 반대 작업하는데 걸리는 시간

## 16pg.

Disk Management  

physical formatting(by manufacturer)
- sector data 구조 = header, data area, trailer
- header 및 trailer에 secter num + ECC 포함

logical formatting(by OS)
- disk를 하나 이상의 cylinder 그룹으로 분할
- logical formatting or file system 만들기

boot block
- 시스템 초기화에 필요
- ROM에 저장된 tiny bootstrap program
- disk의 boot block에 전체 bootstrap loader program 포함 -> 부트 블록을 포함하는 부트 파티션을 가진 디스크 = (부트 디스크 또는 시스템 디스크)

bad sector
- OS에 의해 유지(IDE disk)되거나 disk controller에 의해 유지(SCSI disk)
- ex> sector sparing or slipping

## 17pg.

500번 random disk read(read할때마다 seek, rotation, transfer)를 FIFO order로 하는데 걸리는 시간

500번하니깐 3개 더한걸 500 곱하기  

## 18pg.

sequential disk면?
- 각 한번씩만
- 추가 head or track 전환 필요할 수 있음. 이떄 +1ms
- track buffer를 사용하여 일부 sector에서 순서대로 읽을 수 있음. 이때 -2ms

## 19pg.

잘 모르겟다 ㅋ  
수업시간에 안했으니 넘겨~  

## 20 ~ 22pg.

Scheduling Disk Requests
- OS는 각 disk당 disk requests의 queue를 유지한다
- 여러개의 outstanding I/O request를 고려해라 -> device controller가 동시에 여러 I/O request를 관리할 수 있는경우

input: A set of disk requests  
input: disk state(head position, direction etc)  
output: the next request to handle  

Goal
- throughput(ops/sec) 최대화
- fairness 최대화
- starvation 피하기
- real time concerns(ex> life threatening?)

## 23 ~ 27pg.



![image](https://github.com/KANG0203/OS/assets/144585363/c65b5d39-3406-482e-9999-0eb58b6d0853)

FIFO  
- queue를 보면 request의 track number가 순서대로 들어와 있다.  
- 저 순서대로 head가 움직이면서 scheduling 된다  

pros
- fair and simple
- application이 기대하는 order

cons
- 도착이 disk의 random 위치에 발생할 수 있다. -> 존나 멀리 있는 경우 ㅈㄴ 멀리 이동해야함
- 급격한 변동 발생 가능성 -> average service time이 나쁠 수 있다.

![image](https://github.com/KANG0203/OS/assets/144585363/eedd0864-bb6e-49ba-864f-aba0a10b0b9d)
ppt 그림 이상하니 이거 참고  

SCAN (a.k.a. Elevator Algorithm)
- Take the closest request in the direction of trave -> direction이 있어서 그 방향으로만 쭉 갔다가 방향 바꿔서 쭉 갔다가 함
- scan은 끝까지 간다 쭉~ -> 이를 해결하기 위해 request가 있는 곳까지만 가는 것이 LOOK 이다.

pros
- 각 요청에 대한 제한된 시간 -> 방향 있어서 starvation 안생김

cons
- 방향과 반대 끝은 worst case 발생

![image](https://github.com/KANG0203/OS/assets/144585363/29bd7576-d083-4700-acec-c58870668a3a)

CSCAN (Circular SCAN)
- SCAN과 비슷한데 wrap around -> 한 방향만 고려 그림은 오른쪽만 service
- request가 있는 곳까지 가는게 C-LOOK

pros
- uniform service time
- fair, starvation-proof

cons
- return할떄 아무것도 안함

![image](https://github.com/KANG0203/OS/assets/144585363/1eccd8bd-c6a3-4ba9-938d-e4f42aee2418)

R-CSCAN
- CSCAN인데, trach switch < rotational delay을 고려한다.
- 지금 그림은 1->3으로 가는 rotational delay보다 1->2로 가는 track switch가 더 작아서 2번부터 실행하는 거임

## 30pg.

Linux Disk Scheduling Algorithms  

Cyclic elevator algorithm가 디폴트  

Deadline scheduling
- 각 요청에는 deadline이 있음/ cyclic elevator 사용
- 실시간 process에 priority 부여, 그 외에는 fair하게 처리
- starvation 없음(real time process가 과도한 일을 하는 경우 제외하고)

Anticipatory scheduling(예측 스케줄링)
- I/O 요청 다음에 근처 다른 요청이 빠르게 이어질 것으로 가정
- 요청한 서비스 후 wait해서 근처에 요청이 곧 발생하면 서비스하고, 아니면 cyclic elevator 수행
- fair, real time 지원 없음, starvation 없음

CFQ 안함  

## 31pg.

Storage Availability  

Storage reliability
- 가져온 데이터는 저장한 것과 일치한다.
- transaction, redo logging 등

Storage availability
- 내가 원하는 data가 있다
- 더 많은 disk가 있으면 어떤 disk가 고장날 확률이 높아짐
- failure가 독립적이며 data가 k개의 disk에 분산되어 있으면 Data available ~prob(disk working)^k 교재 prof 오타
- 큰 k는 시스템이 작동할 확률은 0에 수렴

Non-recoverable read errors
- disk device가 data를 잃을 수 있다
- 1015bit read당 한 sector
- 원인 -> physical wear, 인근 track에 대한 반복된 write

## 32pg.

RAIDs(Redundant Array of Independent (or Inexpensive) Disks)
- 성능을 위해 여러 drive 사용
- data avaliability는 어떻게 될까

avaliability를 위해 data 복제
- RAID 0: 복제 없음
- RAID 1: 데이터를 두 개 이상 disk에 걸쳐 mirror
- RAID 5: data를 여러 disk에 분할하고, single disk failure로부터 복구하기 위한 여분의 data를 가짐
- RAID 6: RAID5와 유사하지만, 두 개의 disk failure로부터 복구하기 위한 여분의 data 가짐

## 33pg.

RAID 1: Mirroring
- write를 두 disks에 복제
- read는 두 disks 중 어느 하나로 이동 ㄱㄴ

prob
- read는 paraellel 가능해서 성능 좋음

cons
- write일 때 둘 다 써야해서 성능 향상 x
- space overhead 커짐

## 34pg.

Parity
- RAID 5에서 쓰임
- parity block: block1 xor block2 xor block3
- 다른 block에서 누락된 어떤 block이든 재구성 가능
- block 1을 write하는 경우 parity block도 write 해야 한다.

## 35pg.

RAID 5 : Rotating Parity
- parity 정보를 분산시켜 한 parity block에 ㅈㄴ write 되는걸 분산시켜 전체 workload balancing

## 36pg.

RAID Update  

mirroring
- 모든 mirror에 write

RAID 5 -> one block에 writㄷ하는 경우
- read old data block
- read old parity block
- write new data block
- write new parity blokc
- new parity = old data xor old parity xor new data

RAID-5: to write entire stripe
- write data block and parity

## 37pg.

e.g. Availability by RAID  
답에 10^15가 아니라 1/10^15인듯 저거 틀렸었다 했음  

solution
- RAID 6: 두 개의 여분 disk block -> parity, linear feedback shift
- Scrubbing: background에서 disk sector를 읽어 숨겨진 오류를 찾고 수정

## 39 ~ 40pg.

Flash Memory  
- write하는 경우 floating gate로 전자가 채워진다
- erase 하는 경우 floating gate의 전자를 뺴내온다

## 41pg.

Flash Memory  

write는 clean cell에 이루어져야 한다. 원래 위치에서 update가 없어야 한다.  
- write 전에는 large block erasure가 필요
- erasure block: 128 ~ 512kb
- erasure time: 몇 ms -> 굉장이 커서 bacground에서 일어나야 한다
- limited erase cycle: 만 ~ 10만

Latency
– Read page : ~ 20 us
– Write page : ~ 200 us
– Erase block : ~ 2 ms

## 42pg.

Solid-State Drive (SSD a.k.a. Flash Drive)
- HDD(Hard disk drive) interface가 있는 flash memory

pros
- moving part가 없어서, seek나 rotational latency가 없다
- HDD보다 신뢰도 높고 빠름

cons
- MB당 더 비쌈 -> 용량 적음
- limited erase cycle

## 43pg.

HDD
- sector는 read/write unit

Flash Drive
- block은 erase unit
- page는 program(read/write) unit

## 44pg.

FTL(Flash Translation Layer)

flash device firmware는 logical page num을 physical location을 mapping
- live page를 new location에 복사한 erasure block을 garbage collect해서 erase -> 동시에 저장된 block이 동시에 삭제되면 더 효율적
- wear-leveling: 각 physical page를 제한된 num으로만 write
-  더 이상 작동하지 않는 page를 다시 mapping(sector sparing)

device user에게 transparent  

## 45pg.

Flash Drive Specification Category
- 쭉 읽어보자

## 46pg.

File System - Flash
- erase 중에 "live block"(page in flash memory)은 새로운 위치로 remapping

flash device는 어떻게 block이 live인지 알까?
- TRIM command -> file system이 더 이상 사용되지 않는 block을 device에 알림(HDD에는 필요 없음)

## 47pg.

SSD 작동 방식
- 처음엔 no data
- 6칸 write
- user가 data delete -> page는 OS에 의해 not in use로 marked되었는데 SSD에 data 남아있음
- TRIM command가 SSD controller에게 page가 invaild data를 포함한다 알림 -> page clean시킴
- data가 SSD로 write back -> invalid data cleaned -> page에 data 쓰일 수 있음

