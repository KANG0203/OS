## 2pg.

Cache
- data를 copy하여 원래보다 더 빠르게 access
- hit: cache has copy, Miss: cache dosen't have copy

cache block
- cache 저장 단위(multiple memory location)

Temporal locality
- 동일한 메모리 위치를 여러번 참조/ loop 내의 명령어

Spatial locality
- 근처 위치 참조/ loop 내의 데이터

## 4 ~ 5pg.

read
- cache에 address 있으면 value 읽음
- 없으면 disk에서 가져옴?

write
- write through - cache에 값 저장하고, 다음 level storage에도 바로 저장
- write back - cache block이 교체될 때까지 cache에 저장

## 6pg.

Cache lookups
- fully associtative - 병렬 search
- direct mapped - 특정 location mapping
- set associative - cache 여러개

## 10pg.

Demand paging
- 필요할 때만 page를 memory로 가져온다.
- 적은 I/O, memory 필요
- 빠른 응답
- more processes

page fault trap
- cpu가 swapped in 되지 않은 page를 이용하면 page fault 발생
- 잘못된 참조면 abort
- memory에 없으면 디스크에서 메모리 가져온다.
- page table의 valid bit는 invalid로 초기화

## 11pg.

Steps Handling a Page Fault Trap
- 먼저 page table을 참조하는데 invalid인 경우 trap을 발생시킨다.
- memory에 없는 경우 disk에서 page를 가져온다.
- frame을 할당할 때 empty page frame을 생성하거나, old page를 대체한다.
- page table 갱신
- instruction 재시작

## 12 ~ 13pg.

흠 아마 page B를 적재하면서 page A를 빼고, invalid 시킨 것 같다.  

## 14pg.

Demand Paging in H/W-loaded TLB
- TLB miss
- page table 탐색
- page fault
- trap to kernel
- v.addr를 file + offset으로 변환
- page frame 할당(필요하면 evict page)
- disk block을 page frame으로 읽음
- DMA(direct memory access) 끝나면 disk interrupt
- page를 valid로 바꿈
- fault가 발생한 instruction에서 재개
- TLB miss
- page table 탐색하여 TLB에 가져옴
- 재시작

## 15pg.

Demand Paging in S/W-loaded TLB
- page table을 탐색하지 않고 trap to kernel
- 그리고 쭉 하다가 load tlb entry

이러한 이유는 S/W에서는 translation을 SW가 하기 때문이다.  

## 16pg.

Allocating a Page Frame
- evict할 old page 선택
- old page를 참조하는 모든 page table entry 탐색 -> page frame이 shared된 경우
- 각 page table entry invalid
- 관련된 tlb entry 제거 -> 그리고 invalid page table entry copy
- write back 필요하면 함

## 17pg.

어떻게 page가 modified된지 알까?  

모든 page table entry는 bookkeeping을 가지고 있다.
- 수정되면 store instruction에서 HW에 의해 설정, TLB 및 page table entry에 모두 적용
- 최근에 사용되면, 각 TLB miss에서 page table entry에 HW에 의해 설정

Bookkeeping bits는 OS에 의해 재설정
- page의 변경이 disk로 flushed될 때
- page가 최근에 사용되었는지 추적하기 위해

## 18 ~ 19pg.

write를 한 경우 TLB, page table 둘 다 dirty bit를 yes로 설정한다.  

## 20pg.

Physical page
- modified - modified page를 가리키는 page table entry
- recently used - recently used를 가리키는 page table entry

MIP
- core map에 dirty/use bit를 저장하는 것이 더 간단함
- core map이란 physical page frame의 map

## 21 ~ 22pg.

Emulating modified bit (H/W Loaded TLB) - dirty used bit를 안쓰고 모방하는 방법

Kernel can emulate a modified bit
- clean page를 read only로 set
- page를 처음 쓸 때 kernel로 trap
- kernel이 R/W로 바꾼다
- 실행 재개

Kernel can emulate a recently used bit:
- recently used를 invalid로 set
- 처음 read/write할 때 kernel로 trap
- kernel이 R 혹은 R/W로 mark
- 실행 재개

Kernel needs to keep track of both
– Current page table permission (e.g., read-only)
– True page table permission (e.g., writeable, clean)

그니깐 dirty used bit를 안쓰고, access permission을 통해 dirty와 used를 표현  

## 23pg.

Emulating modified/use bits (S/W Loaded TLB)  

MIPS TLB enrieds 는 modified/unmodified bit를 가지고 있다.
- TLB에 entry가 없거나, unmodified page에 write를 하는 경우 kernel로 trap

TLB read miss
- page가 clean하면 read-only로, dirty면 R/W로 TLB entry에 load
- page가 recently used되었다고 mark

TLB write to an unmodified page
- page table에 수정되었다고 표시
- tlb entry를 R/W로 설정 (이미 tlb에 있음)
- page가 recently used되었다고 mark

On TLB write miss
- page table에 수정되었다고 표시
- R/W로 load tlb entry (원래 tlb에 없음)
- page가 recently used되었다고 mark

## 24pg.

explicit read/write syscall
- syscall을 사용하여 data를 user process로 복사
- application이 data operate
- syscall을 사용하여 data가 kernel로 복사

Memory-mapped files
- file을 memory segment로 열기
- program은 segment memory에 load/store을 사용하여 file에 implicitly operating
- memory에 아직 파일 일부가 없으면 page fault
- kernel이 missing block을 memory로 가져오고 process 재개

## 25pg.

Advantages of Memory-Mapped Files
- programming을 간소화 - copy in/ copy out 대신에 file에 직접 작용
- zero-copy I/O - data가 disk에서 frame으로 direct로 가져옴
- Pipelining - 모든 page가 채워지기 전에 process가 작업 가능
- interprocess communication - shared memory segment vs temporary file

## 26pg.

From Memory-Mapped Files to Demand-Paged Virtual Memory  

모든 process segment는 disk file을 기반
- code segment -> 실행 file 코드 부분
- data, heap, stack segment -> temp file
- 공유 라이브러리 -> code file 밑 temp data file
- mmf -> mmf
- 프로세스 종료되면 temp file 삭제

file buffer와 process간의 unified memory 관리  

## 27pg.

Cache Replacement Policy  
- new entry가 미래에 더 많이 사용될 것으로 가정
- direct mapped caches에서는 필요 없다.
- cache miss를 줄이자.

## 30pg.

FIFO - first in first out
- program이 cache보다 큰 memory를 사용?하는 경우 worst case

## 31pg.

MIN
- 미래에 가장 오랫동안 사용되지 않을 cache entry 교체
- Optimality proof based on exchange: 더 빨리 사용되는 entry를 제거하면 더 빨리 cache miss 발생

LRU(least recently used)
- 과거에 가장 오랫동안 사용 안한 entry 교체
- MIN의 approximation

LFU(least frequently used)
- 최근에 가장 적게 사용된 entry 교체

## 32pg.

LRU는 과거에 사용한 순으로 교체  
MIN은 ABC가 미래에 사용되는게 있어서 D부터 교체 그다음 EAB순으로 미래에 사용하므로 C 교체, 마지막으로 DAE순으로 사용해서 B 교체  

## 33pg.

LRU보면 C를 가장 옛날에 새용해서 교체, 그다음 D 교체  
FIFO는 걍 들어온 순, + 신경 안쓴다  
MIN은 흠.... 뭔가 이상한데 C가 교체될게 아니라 B가 교체되어야 하는거 아닌가...? 애들한테 물어보자  

## 34 ~ 35pg.

page frame이 더 많으면 page fault가 줄어들까?  

다음 페이지를 보면 3개인 경우 page fualt가 9번, 4개인 경우 10번 일어남.  
즉 page frame이 더 많다고 page fault가 줄어드는 건 아니다. -> Belady's anomaly  

## 36pg.

Clock Algorithm
- approximate LRU
- use bit를 확인하여 1이면 0으로 바꾸고 넘기고, 0이면 대체

## 37pg.

N-th Chance
- 여러번 기회를 더 주는 것이다.
- 코드를 보면 우선 use bit가 1이면 0으로 바꾼다.
- use bit가 0이면 notInUseSince가 N이 될 때까지 1을 더하며 기회를 준다.
- N이 되면 대체

## 38pg.

Clock and Nth Chance can run synchronously
- page fault handler에서 eviction 함수 부름
- 먼저 이전에 변경된 내용 write back 해야함

asynchronously
- recently unused인 clean page pool을 유지하는 thread를 생성
- unused dirty page를 찾아 write back
- unused clean page를 찾아 invalid로 하고 pool로 이동
- page fault시 pool에 요청한 page 있는지 확인
- 아니면 해당 페이지 evict

## 40pg.

How Many Pages Allocated to Each Process
- 각 process는 최소 page 수가 필요하다.
- fixed alloc, priority alloc

## 41pg.

equal allocation - 예시 보기  

proportional allocation - process 사이즈에 따라 할당, 예시 참고  

## 42pg.

Priority Allocation
- proportional alloc에서 size 말고 priority 사용
- 만약 process 가 page fault 생성하면, 낮은 priority를 가진 process에서 frame 교체

## 43pg.

Global replacemen
- process는 모든 frame 집합에서 교체 frame 선택, 한 process가 다른 process에서 frame 가져갈 수 있다.

Local replacement 
- 각 process는 할당된 frame 집합에서만 선택

## 44pg.

What to do when not enough memory?  

Trashing
- process가 가지고 있는 memory보다 더 원할 때
- 한 page를 가져올 때마다 곧 찹조될 내용의 다른 page가 삭제된다
- process는 page가 disk에서 가져와질 때가지 blocked되어 시간 소비
- I/O 장치가 활용되지만, 시스템은 큰 유용한 작업 수행 못함

원하는 것 - disk size의 virtual memory와 physical memory의 access time  
가진 것 - memory with access time == disk access  

## 45pg.

Thrashing  

process가 빈번히 memory가 아닌 곳에서 page 참조
- I/O를 기다리는 데 더 많은 시간을 소비하고 일하는 데는 덜 시간을 소비

Thrashing 발생 원인
- process doesn’ t reuse memory, so caching doesn’ t work
- process does reuse memory, but it does not “ fit”
- individually, all processes fit and reuse memory, but too many for system.

## 46pg.

Making the Best of a Bad Situation  

Single process thrashing?
- 만약 process가 memory에 not fit or not reuse, OS는 damage를 제어하는 것 이외에 할 수 없다.

System thrashing?  

여러 process들이 합쳐져 thrashing이 발생한다면
- 각 process가 얼마나 많은 memory를 필요하는지 파악
- memory 요구 사항이 충족될 수 있는 그룹에서 process를 실행시키기 위해 scheduling priorities 변경(shedding load)
- 새 process가 시작되려고 할 때 거부 가능(admission control)

## 47pg.

Working Set Mode  

working set - 합리적인 cache hit rate를 위해 cached해야하는 memory location의 집합  
size of working set - 중요한 threshold  
동일한 program 실행 중에 size 변경될 수 있다.  

## 48 ~ 49pg.

cache size가 커질수록 hit rate 커짐  
시간에 따라 working set이 변하여 hit rate도 변함  

## 50 ~ 51pg.

많은 시스템의 caching 동작은 working set model로 잘 특성화 되지 않는다. -> Zipf distribution로 해결  

Zipf distribution
- "어떤 단어의 빈도는 빈도 표ㅢ 순위에 반비례"
- 가장 빈번한 단어는 두번째로 빈번한 단어보다 대략 두배 자주, 세번째 보다 대략 세 배 자주 나타날 것이다.

그림 보면 rank가 낮아질수로 popularity도 지수적으로 낮아짐.  

## 53pg.

cache 크기를 증가시키면, hit rate가 증가하지만, 이는 점차 수익 감소이다. (log scale)  

## 54 ~ 57pg.

Page Coloring  

cache size가 page size보다 훨씬 크면 어떻게 되냐
- Direct mapped or set associative
- 같은 cache line에 여러 page map

그림 보면 컬러링 된 곳에 할당 안하게 하는 듯 하다.  

