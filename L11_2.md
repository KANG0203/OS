## 2pg.

file system의 구성 요소
- file system structure
- naming and directories
- efficiency and performance
- reliability and protection

지금까지 reliability빼고 다 다룸. 이번 챕터에서는 reliability에 대해서 다룬다.  

## 3 ~ 4pg.

Disk가 전원을 잃거나 machine software가 충동할 경우 어떤 일이 발생할까?
- 진행 중인 일부 operation이 완료
- 진행 중인 일부 operation이 손실
- block에 overwrite가 부분적으로만 완료될 수 있다

file system은 최소한의 durability(내구성)을 원한다
- 이전에 저장된 데이터는 failure(어쩌면 복구 된 후)에 관계 없이 검색 가능해야 한다.

성능을 위해 모든 것이 cached되어야 한다 -> read에서는 괜찮지만 write에서는 어떨까  

write through
- 즉시 disk에 write, 느리다(write가 완료될 때까지 기다려야 한다)

write back
- disk에 수정을 나중에 한다(예로 replaced될 때), crash에서 data를 손실할 수 있다.

## 6pg.

Multiple Updates  

mutiple 업데이트가 필요한 operations를 수행하는 도중에 carsh 발생  

file을 directory간으로 이동하는 경우
- 이전 directory에서 file 삭제
- 새 directory에 추가

새 file 생성
- disk에 header, data에 대한 공간 할당
- 새로운 header를 disk에 기록
- directory에 file 추가

위와 같은 경우 가운데에서 system crash가 발생하면 어떻게 해야 할까
- write through를 사용해도 문제가 발생한다.

## 7pg.

File System Reliability Problem  

single logical file operation은 여러 physical disk block에 대한 업데이트를 포함할 수 있다.
- inode, indirect block, data block, bitmap, ...
- remapping을 하면, 하나의 physical disk block에 대한 single update가 여러 개의(even lower level) update를 필요로 할 수 있다.

physical level에서 operation은 한 번에 하나씩 완료 -> 성능을 위해 concurrent operation  

crash가 언제 발생하던 consistency를 보장하는 방법이 무엇일까  

## 8pg.

Approaches to Cope with Crash  
- don't crash
- disk가 항상 consistent하기 위해 정해진 순서로 multi-step disk update
- transaction처럼 multi-step disk update -> 모든 step이 실행되거아 실행되지 않거나

## 9pg.

Careful Ordering  
- 특정 순서의 sequence operation -> 작업이 안전하게 중단될 수 있도록 설계
- Post-cash recorver(충돌 이후 복구) -> operationd의 진행 여부를 알기 위해 data structure을 읽어 필요한 경우 clean up/finish
- FAT, FFS(fsck), mamy app-level recovery schemes에서 채택된 방식

## 11pg.

FAT : Append Data to File  

Normal operation
- data block 추가
- data block 가리키는 pointer 추가
- 새 file tail을 새 MFT entry를 가리키도록 업데이트
- file head의 access time 업데이트

Recovery
- MFT 확인
- entry가 unlinked면 data block 삭제
- access time이 incorrect이면 update

## 12pg.

FAT : Create New File  

Normal operation
- data block 할당
- data block을 가리키는 MFT entry update
- file name -> file number로 directory 업데이트
- directory 수정 시간 업데이트

Recovery
- MFT 확인
- any unlinked files(not in any directory), delete
- 수정 시간을 업데이트 안해준게 있는지 scan

## 13pg.

UNIX Approach
- meta data와 user data 둘 다 consistency 성취
- meta data는 file system이 logically consistent하게 보호하기 위해 필요 ex> directories, bitmap, file headers, indirect blocks
- data는 user bytes

## 14pg.

Meta-Data Consistency (Ad Hoc)  

meta-data consistency -> 특정 순서로 synchronous write-through  
user data consistency -> 30초마다 write back  

meta data를 위해 unix는 synchronous write through 사용
- multiple update가 필요한 경우 이를 특정 순서로 진행한다
- crash가 발생한 경우, fsck(file system check)을 실행 이는 "in progress" operation을 채크해서 진행 중인 작업에 대해 수정, 이를 위해 전체 disk를 internal consistency를 확인하기 위해 scan

EX>
- file created, but not yet put in any directory -> delete file
- blocks allocated, but not in bitmap -> update bitmap

## 15pg.

UNIX : Create a File  

Normal operation
- data block 할당
- write data block
- inode 할당
- write inode block
- free blocks에 대한 bitmap update
- name -> number로 directory 업데이트
- directory 수정 시간 업데이트


Recovery
- inode table 스캔
- unliked file이 있으면 delete
- free block bitmap 과 inode tree를 비교
- 누락된 update/access time을 찾기 위해 directory 스캔

## 16pg.

UNIX : Move a File  

Normal
- old directory에서 filename 삭제
- new directory에 filename 추가

Recovery
- 모든 directory를 스캔하여 live files의 set를 결정
- valid inodes를 가진 directory에 없는 file을 고려한다 -> 새 파일 생성중? 파일 이동중? 파일 삭제중?

## 17pg.

User Data Consistent
- write back 사용 or sync 사용하여 disk에 즉각 write
- no guarantee block는 disk에 순서 없이 쓰인다
- 때때로 meta data의 consistency로만 충분하다

vi에서 file 변경을 disk에 어떻게 저장할까
- temp file에 new version write
- old version을 다른 temp file로 이동
- new version을 real file로 이동
- old version을 unlink

crash 발생하면 temp area 확인하여 만약 어떤 file이 거기 있다면 문제가 있을 수 있다고 email 보냄  

## 18pg.

Application Level  

normal
- 각 open file을 app folder에 write
- 변경 사항을 backup file에 저장
- backup file의 이름을 file로 변경(atomic operation)
- 정상 종료 시 app folder에서 list 삭제

Recovery
- 시작 시 열린 파일이 있는지 촥인
- 파일이 열려있으면 backup file 확인
- backup file이 있다면 user에게 version을 비교하라고 ask

## 19pg.

careful ordering pros
- disk drive에서 최소의 지원으로 work
- multi-step operation에서 잘 work

cons
- 실패 후 time-consuming recovery를 필요로 한다
- 각 작업을 안전하게 중단 가능한 일련의 write로 줄이기 어렵다
- counvurrently하게 발생한 multiple operation이 발생할 때 consistency를 성취하기 어렵다

## 20pg.

More Careful Ordering : Soft Update  

언제나 consistency 유지
- consistency를 유지하는 순서로 cache 업데이트
- cache 내용을 disk에 쓰는 순서는 cache가 업데이트된 순서와 동일

## 21pg.

origianl disks에서는 disk에 A를 먼저 쓰고 B를 쓴다.  
disk with write buffers의 경우 먼저 disk cache에 A와 B를 쓰고 그다음 disk platter로 옮기는데 이때는 순서가 바뀔 수 있다.  
그래서 이를 보안하기 위해 Flush를 추가하여 disk cache가 있어도 원래 순서를 유지하여 platter에 갈 수 있다.  

## 22pg.

Copy-on-write  

file system을 업데이트 할 때, update를 포함하여 file system에 new version write
- 동일한 공간에 undate 안함
- 기존에 변경되지 않은 disk block을 재사용

한 operatino마다 새 version을 써서 expensive해보일 수 있다. 하지만
- update는 batched가 가능하다. 이는 하나하나 하는걸 모아서 한번에 업데이트 하는 방식이다
- 거의 모든 disk write는 parallel로 발생

## 23 ~ 24pg.

그림을 보면 data blocks D를 update하는 과정이다.  
이때 overwrite하는 것이 아닌, 새 공간에 update한다. 이때 D와 연결되어있는 모든 것을 새로 생성한다.  
그리고 기존에 update 전 space는 garbage collection 한다.  

## 25pg.

batch update로 여러개가 한번에 setup되는 것을 보여준다.  

## 26pg.

Copy-On-Write Garbage Collection  

write efficiency를 위해 연속된 일련의 free block를 원한다
- 모든 block groups에 고르게 분산시킨다
- update는 dead block을 흩뿌린다

read efficiency를 위해 함께 읽는 data가 동일한 block group에 있기를 원한다
- write anywhere는 관련 data를 흩뿌린다

-> background에서 live/dead block을 합친다.  

## 27pg.

Copy-on-write pros
- 실패에 관계없이 올바르게 동작
- 빠른 복구(root block array)
- 높은 throughput(batched인 경우 가장 효과적)

cons
- 높은 지연 가능성(new version 계속 만들어야 해서)
- small changes에도 많은 write 필요
- garbage collection은 성능에 필수적

## 28pg.

Logging
- write changes to a log
- intention list: 우리가 하려고 하는 changes에 대한 목록
- log 는 append-only

log에 적었으면, disk의 data structure에 changes 안전하게 적용
- recovery는 log를 읽어서 어떤 changes가 의도되었는지 확인

changes가 copy되면 log를 안전하게 제거  

## 29pg.

Transaction - work를 그룹화하여 다음과 같은 특성 가지도록 한다
- atomic: 일어나거나 일어나지 않거나
- Serializable: transacton은 하나가 끝나면 다른 것이 시작되는 것처럼 나타남
- Durable: 한번 일어나면 계속해서 일어남, Critical section은 atomic하고 serialization하지만 durable은 아님
- need two more items. commit은 transaction이 완료될 때, rollback은 transaction중에 오류 발생하면 처음으로 돌림

Metaphot
- 일련의 작업을 임시로 수행
- commit에 도달하면 ㄱㅊ 근데 그렇지 않으면 Rollback

## 30pg.

Transaction Implementation  
- disk에 여러 update를 어떻게 만드는지의 문제를 해결하기 위해, 여러 update를 single disk에 write

transaction의 모든 변경 사항에 대한 "redo(재실행)" log를 disk에 유지
- log는 지워지지 않아 모든 수행 내용 기록
- log에 양쪽의 변경 사항이 모두 기록되면 transaction이 commit
- 그런 다음 disk에 대한 변경을 "write behind", commit 이후 crash 발생하면 log를 다시 실행하여 update가 disk에 도달할 수 있도록 한다.

## 31 ~ 37pg.

별로 안어렵다 걍 보자  

중요한건 commit 전에 crash 발생하면 changes 무시하고, commit 이후에 발생하면 log 다시 실행  
commit 쓰다가 crash 발생하지 않게 primitive atomic operation 필

## 38pg.

Redo Logging
- prepare: log에 모든 changes(in transaction) write
- commit: single disk write로 transaction을 durable하게
- Redo: copy changes to disk
- grabage collection: log 수거

Recovery
- log 읽기
- Redo any operation for committed transactions
- garbage collect log

## 39pg.

Performance  

crash 이후 fsck 안해도 된다 -> log만 확인하면 된다  
log written sequentially -> append-only, often kept in flash storage  
Asynchronous write back -> 모든 변경 사항이 commit 전에 logging되고, write back이 이후에 발생하여 순서 중요하지 않음  
multiple transaction 처리 가능 -> 각 log entry에 transaction ID 있음, transaction은 log에 commit record가 있는 경우에만 완료  

## 41 ~ 42pg.

Journaling File Systems  

Journaling File Systems은 모든 file system의 각 update를 transaction으로 기록  
모든 transaction은 log에 기록
- transaction이 log에 기록되면 commit으로 간주
- filesystem은 아직 update 안됐을 수 있다.

log에 있는 transaction은 file system에 asynchronously하게 written
- file system이 modified되면 transaction은 log에서 제거

file system에서 crash 발생하면, 모든 log에 남아있는 transaction은 수행되어야 한다.  

Three journaling levels
- Journal: both metadata and data
- Ordered: metadata only, 하지만 write order 보장, file data는 metadata commit되기 전에 disk에 작성
- writeback: metadata only, write order 보장 안함

## 43pg.

Caveat(경고)
- 대부분의 file system은 내부적으로 transaction model 구현(copy on write, redo logging)
- 대부분의 file system은 개별 syscall에 대한 transaction model 제공(file rename, move)
- 하지만 대부분의 file system은 user data에 대한 transaction model 제공 안함

## 44pg.

copy back이 필요할까?(복사본을 다시 복사?)
- 만약 업데이트가 매우 비용이 많이 들면 어떨까? ex> flash storage, RAID

## 45pg.

log는 data storage이며, copy back 없다
- storage는 contiguous하고, fixed size segment로 분할 -> flash: size of erasure block, disk: 효율적 전송 size
- new block을 empty segment에 log -> dead block을 garbage collect하여 empty segment 생성
- 각 segment는 indrectoin의 추가 level을 포함한다 -> 해당 segment에 저장된 block은 무엇인가

Recovery
- 마지막으로 성공적으로 written된 segment를 찾는다.

## 46pg.

Log-Structured File Systems
- obervation: RAM 비용으로 인해 대규모 cache가 실행 가능, 큰 cache로 인해 write I/O가 지배
- write 성능 최적화해야 한다
- log writing(모든 write를 순차적으로 수행)
- garbage collect (cleaning operation)

pros
- write performance(sequencial write)
- 읽기는 file이 처음부터 끝까지 순차적으로 쓰인 경우에 효율적

cons
- cleaning cost
- file이 그 자리에서 옵데이트 되는 경우 bab

